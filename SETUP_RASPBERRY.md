# üçì Setup para Raspberry Pi com TensorFlow Lite

Este guia configura o projeto para rodar em Raspberry Pi 4 com TensorFlow Lite.

## üìã Pr√©-requisitos

### Hardware
- **Raspberry Pi 4** (2GB m√≠nimo, 4GB recomendado)
- **Cart√£o SD**: 32GB+
- **Fonte de alimenta√ß√£o**: 5V/3A m√≠nimo

### Sistema Operacional
```bash
# Verificar vers√£o
lsb_release -a
cat /proc/cpuinfo | grep model
```

Testado em:
- ‚úÖ **Armbian** (Debian/Ubuntu-based) - RECOMENDADO
- ‚úÖ Raspberry Pi OS (Bullseye/Bookworm)
- ‚úÖ Ubuntu 22.04 ARM64

---

## üöÄ Instala√ß√£o Passo a Passo

### 1. Atualizar Sistema
```bash
sudo apt update
sudo apt upgrade -y
sudo apt install python3-pip python3-venv libatlas-base-dev ffmpeg -y
```

### 2. Criar Ambiente Virtual
```bash
cd ~/Pytorch  # ou seu diret√≥rio
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar Depend√™ncias
```bash
# Atualizar pip
pip install --upgrade pip setuptools wheel

# Instalar depend√™ncias base
pip install numpy scipy PyYAML opencv-python lap

# Instalar PyTorch para ARM (SEM CUDA)
# IMPORTANTE: Use vers√£o pr√©-compilada para ARM
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# Instalar TensorFlow Lite
pip install tensorflow
```

**Aviso:** A instala√ß√£o do TensorFlow pode levar 10-30 minutos em Raspberry Pi.

### 4. (Opcional) Google Coral TPU
Se tiver Coral TPU USB:
```bash
pip install pycoral
```

### 5. Obter Modelo TFLite

**Op√ß√£o A: Baixar de Hugging Face (MAIS CONFI√ÅVEL)**

```bash
cd weights

# YOLOv5n INT8 (recomendado para Pi)
wget https://huggingface.co/spaces/deepquest/yolov5-tflite/resolve/main/yolov5n-int8.tflite

# Ou YOLOv5s INT8 (mais acurado)
wget https://huggingface.co/spaces/deepquest/yolov5-tflite/resolve/main/yolov5s-int8.tflite

cd ..
```

**Op√ß√£o B: Baixar do GitHub (se op√ß√£o A n√£o funcionar)**

```bash
cd weights

# YOLOv5n
wget https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n-int8.tflite 2>/dev/null || \
wget https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5n-int8.tflite

cd ..
```

**Op√ß√£o C: Converter localmente (seu computador)**

Se nenhum dos links funcionar, converta no seu **Windows/Linux**:

```bash
# No seu computador (N√ÉO no Raspberry)
pip install ultralytics

python3 << 'EOF'
from ultralytics import YOLO

# Carregar modelo
model = YOLO('yolov5n.pt')

# Exportar para TFLite INT8
model.export(format='tflite', imgsz=640, int8=True)

# Arquivo gerado: yolov5n-int8.tflite
EOF

# Depois copiar para Raspberry:
scp yolov5n-int8.tflite usuario@raspberry:~/Pytorch/weights/
```

**Verificar se o arquivo foi baixado:**
```bash
ls -lh ~/Pytorch/weights/*.tflite
```

**Op√ß√£o B: Converter seu pr√≥prio modelo**
```bash
# No seu computador (n√£o no Raspberry)
python3 export_to_tflite.py  # Script que criaremos
```

---

## ‚öôÔ∏è Configura√ß√£o

### Editar `config.yaml`
```yaml
detector_type: "tflite"           # Usar TFLite em vez de YOLOv7
tflite_model: "weights/yolov5n-int8.tflite"
tflite_use_coral: false           # true se tiver Coral TPU

imgsz: 640                        # Mesmo tamanho (TFLite otimiza internamente)
conf_vehicle: 0.45
conf_person: 0.40
conf_bicycle: 0.35

show_window: false                # Desabilitar display (n√£o h√° X11 no Pi)
```

### (Opcional) Criar `.env`
```bash
cp .env.example .env
# Editar conforme necess√°rio
```

---

## ‚ñ∂Ô∏è Executar

### Rodar Detec√ß√£o
```bash
python3 main.py
```

**Sa√≠da esperada:**
```
üîß Usando TensorFlow Lite Detector (Raspberry Pi)...
‚úÖ Modelo TFLite carregado: weights/yolov5n-int8.tflite
   Entrada: [1, 640, 640, 3]
   Outputs: 3

Stream aberto: https://...
Iniciando detec√ß√£o e tracking...

Frame 30 | Tracks: 5 | Total: 12.5
Frame 60 | Tracks: 6 | Total: 18.0
```

### Monitorar Performance
```bash
# Terminal 1: Rodar projeto
python3 main.py

# Terminal 2: Monitorar em tempo real (Armbian)
watch -n 1 'top -bn1 | head -n 10 && free -h'

# Verificar temperatura (Armbian/Debian)
# Pode variar conforme o hardware
cat /sys/class/thermal/thermal_zone*/temp
```

---

## üìä Performance Esperada

### YOLOv5n INT8 em Raspberry Pi 4

| M√©trica | Esperado |
|---------|----------|
| **FPS** | 3-5 FPS |
| **Lat√™ncia** | 200-300ms por frame |
| **CPU** | 80-95% |
| **RAM** | 1.5-2 GB |
| **Temperatura** | 55-65¬∞C (normal) |

### Com Google Coral TPU
| M√©trica | Esperado |
|---------|----------|
| **FPS** | 8-12 FPS |
| **Lat√™ncia** | 80-120ms por frame |
| **CPU** | 30-50% |
| **RAM** | 1.5-2 GB |

---

## üîß Troubleshooting

### Erro: `No module named 'tensorflow'`
```bash
# Instalar novamente (pode levar tempo)
pip install --no-cache-dir tensorflow
```

### Erro: `Illegal instruction (core dumped)`
- Seu Pi usa CPU incompat√≠vel
- Solu√ß√£o: Use imagem Raspberry Pi OS com suporte ARMv7
- Ou: Compile TensorFlow localmente

### Velocidade muito lenta (< 1 FPS)
**Causas poss√≠veis:**
1. RAM insuficiente (verifique com `free -h`)
2. CPU throttling (temperatura alta)
3. Modelo pesado (YOLOv5s em vez de YOLOv5n)

**Solu√ß√µes:**
```bash
# Verificar temperatura (Armbian)
cat /sys/class/thermal/thermal_zone*/temp

# Ou no htop
htop  # Procura pela coluna TEMP

# Usar modelo menor
detector_type: "tflite"
tflite_model: "weights/yolov5n-int8.tflite"  # Menor = mais r√°pido

# Reduzir imagem de entrada
imgsz: 416  # Em vez de 640
```

### Memoria insuficiente durante infer√™ncia
```bash
# Adicionar swap (Armbian)
sudo nano /etc/dphys-swapfile  # Se existir
# Ou criar manualmente:
sudo fallocate -l 2G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

---

## üíæ Salvar Resultados (Headless Mode)

Se n√£o tem display, voc√™ pode salvar v√≠deo com detec√ß√µes:

Edite `main.py` (ap√≥s inicializar detector):
```python
video_writer = None
if not cfg.get("show_window", True):
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video_writer = cv2.VideoWriter(
        'detections_output.mp4',
        fourcc,
        5,  # 5 FPS (estimado)
        (frame.shape[1], frame.shape[0])
    )
```

Depois no loop, ap√≥s `draw_hud()`:
```python
if video_writer:
    video_writer.write(frame)

# No final, antes de sair:
if video_writer:
    video_writer.release()
```

---

## üì§ Transferir V√≠deo do Pi

```bash
# Do seu computador
scp usuario@raspberrypi:~/Pytorch/detections_output.mp4 ./

# Ou com rsync
rsync -avz --progress usuario@raspberrypi:~/Pytorch/ ./backup/
```

---

## üöÄ Pr√≥ximos Passos

1. **Otimizar modelos**: Tentar YOLOv5n, YOLOv5s diferentes
2. **Google Coral TPU**: Se performance n√£o √© suficiente
3. **Quantiza√ß√£o**: Converter modelo para INT8 (mais r√°pido)
4. **M√∫ltiplos Pis**: Usar em rede com load balancing

---

## üìö Refer√™ncias

- [TensorFlow Lite Guide](https://www.tensorflow.org/lite/guide)
- [YOLOv5 Export Guide](https://github.com/ultralytics/yolov5/wiki/Export)
- [Google Coral Docs](https://coral.ai/docs/)
- [Raspberry Pi Performance](https://www.raspberrypi.com/documentation/computers/raspberry-pi.html)

---

## ‚ö° Dicas Finais

- **Sempre use fonte com 5V/3A** (fonte fraca causa resets)
- **Use ventilador** (throttling mata performance)
- **SSD externo** (cart√£o SD √© lento)
- **Monitor de temperatura** (`cat /sys/class/thermal/thermal_zone*/temp`)
- **Armbian geralmente tem melhor performance** que Raspberry Pi OS

**Boa sorte! üçìüöÄ**
